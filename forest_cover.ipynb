{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0daf75bfb52ae23",
   "metadata": {},
   "source": [
    "# Forest Cover Type Prediction: Data Cleaning and Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b50fb29720d5",
   "metadata": {},
   "source": [
    "This notebook performs data cleaning and exploratory data analysis (EDA) on the Forest Cover dataset. The primary goal is to preprocess the data, handle missing values, and visualize key relationships between features and the target variable, Forest_Cover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7549a144dc196fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 1: Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c914309332b5a4b",
   "metadata": {},
   "source": [
    "First, load the necessary libraries and the dataset and define the data types for each column to ensure they are read correctly."
   ]
  },
  {
   "cell_type": "code",
   "id": "ade9989e9171be64",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the data types for each column to ensure correct loading\n",
    "# 'key_list' contains the initial numerical columns and the target variable.\n",
    "key_list = [\n",
    "    'Elevation',\n",
    "    'Aspect',\n",
    "    'Slope',\n",
    "    'Horizontal_Distance_To_Hydrology',\n",
    "    'Vertical_Distance_To_Hydrology',\n",
    "    'Horizontal_Distance_To_Roadways',\n",
    "    'Hillshade_9am',\n",
    "    'Hillshade_Noon',\n",
    "    'Hillshade_3pm',\n",
    "    'Horizontal_Distance_To_Fire_Points',\n",
    "    'Forest_Cover'\n",
    "]\n",
    "# 'value_list' defines the corresponding data types.\n",
    "value_list = [\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'object' # Forest_Cover is an object since it's a categorical target\n",
    "]\n",
    "\n",
    "dtype_dict = dict(zip(key_list, value_list))\n",
    "# Add the 40 Soil_Type columns and 4 Wilderness_Area columns, which are one-hot encoded and should be integers.\n",
    "for i in range(1, 41):\n",
    "    dtype_dict[f'Soil_Type{i}'] = 'Int64'\n",
    "\n",
    "dtype_dict.update({\n",
    "    'Neota': 'Int64',\n",
    "    'Rawah': 'Int64',\n",
    "    'Comanche Peak': 'Int64',\n",
    "    'Cache la Poudre': 'Int64'\n",
    "})\n",
    "\n",
    "# Load the data from the CSV file using the predefined data types.\n",
    "forest_data = pd.read_csv('./dataset/forest_cover.csv',\n",
    "                          dtype=dtype_dict,\n",
    "                          on_bad_lines='skip',\n",
    "                          engine='python')\n",
    "# Remove the unnamed index column that often appears when saving dataframes to CSV.\n",
    "forest_data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# forest_data.dtypes\n",
    "forest_data.shape\n",
    "# forest_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f07d933f0f42e53f",
   "metadata": {},
   "source": [
    "Find out the type of different columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "80696b49083bfc6e",
   "metadata": {},
   "source": [
    "columns_data_types = forest_data.dtypes.reset_index()\n",
    "columns_data_types"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5511dee83113d57d",
   "metadata": {},
   "source": [
    "Calculate the missing value rate for each column."
   ]
  },
  {
   "cell_type": "code",
   "id": "23f71c4895b4c6c2",
   "metadata": {},
   "source": [
    "columns_names = forest_data.columns.values\n",
    "columns_missing_rate = forest_data.isna().mean().round(5).reset_index()\n",
    "columns_missing_rate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f363743ce61049f1",
   "metadata": {},
   "source": [
    "Merge the data types and missing value rates into a single dataframe for easy viewing and export.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8064ab073ff57c5",
   "metadata": {},
   "source": [
    "data_type_missing_value = pd.merge(columns_data_types, columns_missing_rate, on='index')\n",
    "\n",
    "data_type_missing_value.rename(columns={'index': 'column', '0_x': 'type', '0_y': 'missing_rate'}, inplace=True)\n",
    "data_type_missing_value.to_csv(\"missing_value.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "25b5cba20187203b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 2: Visualizing Missing Values and unique value of columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf111b8a1157f86",
   "metadata": {},
   "source": [
    "Create the chart to show missing value rate"
   ]
  },
  {
   "cell_type": "code",
   "id": "dbcb83f2621bd2a2",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(data_type_missing_value['column'], data_type_missing_value['missing_rate'], color='skyblue')\n",
    "# Format y-axis to display percentages.\n",
    "plt.gca().yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1.0))\n",
    "\n",
    "plt.xlabel('Column', fontsize=12)\n",
    "plt.ylabel('Missing Rate', fontsize=12)\n",
    "plt.title('Missing Rate of Different Columns', fontsize=14)\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Ensure the layout is tight to prevent labels from being cut off\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('missing_rate_bar_chart.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c3ed7164649748c7",
   "metadata": {},
   "source": [
    "Get the unique values of each attribute, and make an example showing a maximum of 3 values."
   ]
  },
  {
   "cell_type": "code",
   "id": "1a18bab95ccd6b9",
   "metadata": {},
   "source": [
    "count_unique_attribute = []\n",
    "for name in columns_names:\n",
    "    count = pd.unique(forest_data[name])\n",
    "\n",
    "    # Filter out missing values (like NaN) for the example string\n",
    "    filtered_examples = [item for item in count if pd.notna(item)]\n",
    "\n",
    "    row_data = {\n",
    "        'Attribute': name,\n",
    "        'Count of unique value': len(count),\n",
    "        'Example': \", \".join(pd.Series(filtered_examples[:3]).astype(str)),\n",
    "    }\n",
    "    count_unique_attribute.append(row_data)\n",
    "# export the data to csv file\n",
    "pd.DataFrame(count_unique_attribute).to_csv('count_unique_value.csv', index=False)\n",
    "count_unique_attribute"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f042f18668ad6f29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 3: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1edd90d8315bc9",
   "metadata": {},
   "source": [
    "This step focuses on cleaning the data by handling invalid entries and missing values.\n",
    "\n",
    "Replace rows with incorrect data in Horizontal_Distance_To_Hydrology,Vertical_Distance_To_Hydrology,\tHorizontal_Distance_To_Roadways,Hillshade_9am,Hillshade_Noon,Hillshade_3pm,Horizontal_Distance_To_Fire_Points like negative and out of range. And remove incorrect soil_type rows without certain type"
   ]
  },
  {
   "cell_type": "code",
   "id": "285ec7ac127c0813",
   "metadata": {},
   "source": [
    "# Create a copy of the original dataframe to perform cleaning.\n",
    "forest_data_test1 = forest_data.copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5f7348c93dfa42d",
   "metadata": {},
   "source": [
    "### Handling invalid soil type columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc8216d614d1b9",
   "metadata": {},
   "source": [
    "Filter out invalid soil type rows because it's hard to estimate the real type if there is no exact value. Filling in any type with 1 is not reliable."
   ]
  },
  {
   "cell_type": "code",
   "id": "39006ccba7ab3c07",
   "metadata": {},
   "source": [
    "# filter out wrong soil-type by calculate the sum of them, if the result is 0, remove the row\n",
    "# because soil type columns use one-hot encoding method, which 1 indicates existing and 0 means no. If a whole row has no 1, it's impossible to decide which one is right. As a result, remove these rows to improve the accuracy.\n",
    "soil_type_columns = [f'Soil_Type{i}' for i in range(1, 41)]\n",
    "# fill the nan with 0 to calculate the sum of soil type\n",
    "forest_data_test1[soil_type_columns] = forest_data_test1[soil_type_columns].fillna(0)\n",
    "forest_data_test1.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bae4338a49cc245",
   "metadata": {},
   "source": [
    "# calculate the sum of different soil type\n",
    "forest_data_test1['Soil_Type_Sum'] = forest_data_test1[soil_type_columns].sum(axis=1)\n",
    "forest_data_test1.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7b0b01ce96f89046",
   "metadata": {},
   "source": [
    "# Filter out the rows where the sum of the 40 Soil_Type columns is 0, which means this row is no valid.\n",
    "filtered_df = forest_data_test1[forest_data_test1['Soil_Type_Sum'] == 1].copy()\n",
    "# remove the sum column\n",
    "filtered_df = filtered_df.drop(columns=['Soil_Type_Sum'])\n",
    "filtered_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "92e2c240f91b6487",
   "metadata": {},
   "source": [
    "### Handling Out-of-Range Numerical Values\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "82f60680f3fe0abe",
   "metadata": {},
   "source": [
    "# Define numerical columns to be checked for valid ranges.\n",
    "numerical_cols = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
    "                  'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
    "                  'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "                  'Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "# Define valid ranges\n",
    "ranges = {\n",
    "    'Elevation': (500, 5000), 'Aspect': (0, 360), 'Slope': (0, 90),\n",
    "    'Horizontal_Distance_To_Hydrology': (0, np.inf),\n",
    "    'Horizontal_Distance_To_Roadways': (0, np.inf),\n",
    "    'Horizontal_Distance_To_Fire_Points': (0, np.inf),\n",
    "    'Hillshade_9am': (0, 255), 'Hillshade_Noon': (0, 255), 'Hillshade_3pm': (0, 255)\n",
    "}\n",
    "\n",
    "# Iterate through the defined ranges and replace out-of-range values with NaN.\n",
    "for col, (min_val, max_val) in ranges.items():\n",
    "    if col in filtered_df.columns:\n",
    "        filtered_df.loc[~filtered_df[col].between(min_val, max_val), col] = np.nan\n",
    "\n",
    "filtered_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c0c393b3d6e80d",
   "metadata": {},
   "source": [
    "### Imputing Missing Values\n",
    "\n",
    "Three common imputation methods, median, mean, and mode to fill in the remaining missing numerical values"
   ]
  },
  {
   "cell_type": "code",
   "id": "c52ea8c9f1713876",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a style for the plot for better aesthetics.\n",
    "sns.set_style(\"whitegrid\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f0420299c7623d6",
   "metadata": {},
   "source": [
    "# Define a helper function to fill in missing values using a specified method.\n",
    "def fillInMissing(data, fn):\n",
    "    for key_name in key_list:\n",
    "        if pd.api.types.is_numeric_dtype(data[key_name]):\n",
    "            if fn == 'mode':\n",
    "                # Explicitly get the first mode\n",
    "                fill_value = data[key_name].mode()[0]\n",
    "            else:\n",
    "                fill_value = data[key_name].agg(fn)\n",
    "            print(f'{key_name}  {fn}_value:{fill_value}')\n",
    "            data[key_name] = data[key_name].fillna(fill_value)\n",
    "    print('\\n')\n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b184f632587dd666",
   "metadata": {},
   "source": [
    "# Create copies of the filtered dataframe for each imputation method.\n",
    "filtered_df_test_median = filtered_df.copy()\n",
    "filtered_df_test_mean = filtered_df.copy()\n",
    "filtered_df_test_mode = filtered_df.copy()\n",
    "\n",
    "fill_with_median_path = './plots/fill_with_median_'\n",
    "fill_with_mean_path = './plots/fill_with_mean_'\n",
    "fill_with_mode_path = './plots/fill_with_mode_'\n",
    "\n",
    "# The scenarios list as defined it\n",
    "scenarios = [\n",
    "    {'df': filtered_df_test_median, 'method': 'median', 'path': fill_with_median_path},\n",
    "    {'df': filtered_df_test_mean, 'method': 'mean', 'path': fill_with_mean_path},\n",
    "    {'df': filtered_df_test_mode, 'method': 'mode', 'path': fill_with_mode_path}\n",
    "]\n",
    "\n",
    "# fill in\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    fillInMissing(scenario['df'], scenario['method'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc3eff49192b2b68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 4: Exploratory Data Analysis (EDA) and Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2116e0f162f34",
   "metadata": {},
   "source": [
    " Explore the relationships between different features and the target variable, Forest_Cover. Select numerical features like Elevation and Slope, Categorical Features like Wilderness_Area and soil types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747e05ee3db1b28",
   "metadata": {},
   "source": [
    "### Analyzing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "id": "9afc45ac51f1d76b",
   "metadata": {},
   "source": [
    "# Calculate and print the correlation between Elevation and Slope.\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    correlation = scenario['df'][['Elevation', 'Slope']].corr()\n",
    "    print(f'Correlation between Elevation and Slope {scenario['method']} value: ')\n",
    "    print(correlation)\n",
    "    # Add the calculated correlation to the dictionary in the original list\n",
    "    scenarios[i]['correlation'] = correlation"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc6f85a16c4b4fcb",
   "metadata": {},
   "source": [
    "# Create a heatmap of the correlation matrix.\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    # Get the stored values from the scenario dictionary\n",
    "    method = scenario['method']\n",
    "    correlation = scenario['correlation']\n",
    "    path = scenario['path']\n",
    "\n",
    "    # Create a heatmap of the correlation\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title(f'Correlation Matrix of Elevation and Slope ({method} value)')\n",
    "    plt.savefig(path + 'Elevation_Slope_correlation_heatmap.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ab6bb97e2aaef221",
   "metadata": {},
   "source": [
    "# Create a scatter plot to visualize the relationship between Elevation and Slope.\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    path = scenario['path']\n",
    "    df = scenario['df']\n",
    "    method = scenario['method']\n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='Elevation', y='Slope', data=df)\n",
    "    plt.title(f'Scatter Plot of Elevation vs. Slope ({method} value)')\n",
    "    plt.xlabel('Elevation')\n",
    "    plt.ylabel('Slope')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(path + 'Elevation_Slope_scatter_plot.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5f264ea896c87388",
   "metadata": {},
   "source": [
    "### Relationship with the Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49a3c1892282af",
   "metadata": {},
   "source": [
    "Use box plots and bar plots to understand how `Elevation` and `Slope` relate to the `Forest_Cover` types."
   ]
  },
  {
   "cell_type": "code",
   "id": "c37c5d462a20bfd",
   "metadata": {},
   "source": [
    "# Box plot for Elevation and Forest Cover.\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    path = scenario['path']\n",
    "    df = scenario['df']\n",
    "    method = scenario['method']\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x='Forest_Cover', y='Elevation', data=df)\n",
    "    # Add a title and labels for clarity.\n",
    "    plt.title(f'Distribution of Forest Cover Type by Elevation ({method} value)', fontsize=16)\n",
    "    plt.xlabel('Forest Cover Type', fontsize=12)\n",
    "    plt.ylabel('Elevation', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels to prevent overlap, making them easier to read.\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    # Adjust layout to make sure labels are not cut off.\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot.\n",
    "    plt.savefig(path + 'Elevation_Forest_Cover_boxplot.png')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca94137ada286353",
   "metadata": {},
   "source": [
    "# Box plot for Slope and Forest Cover.\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    path = scenario['path']\n",
    "    df = scenario['df']\n",
    "    method = scenario['method']\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x='Forest_Cover', y='Slope', data=df)\n",
    "    # Add a title and labels for clarity.\n",
    "    plt.title(f'Distribution of Forest Cover Type by Slope ({method} value)', fontsize=16)\n",
    "    plt.xlabel('Forest Cover Type', fontsize=12)\n",
    "    plt.ylabel('Slope', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels to prevent overlap, making them easier to read.\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    # Adjust layout to make sure labels are not cut off.\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot.\n",
    "    plt.savefig(path + 'Slope_Forest_Cover_boxplot.png')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5deda377e7e853fa",
   "metadata": {},
   "source": [
    "# Bar plot for Average Elevation by Forest Cover Type.\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    path = scenario['path']\n",
    "    df = scenario['df']\n",
    "    method = scenario['method']\n",
    "\n",
    "    # Calculate the average elevation for each forest cover type.\n",
    "    average_elevation = df.groupby('Forest_Cover')['Elevation'].mean().reset_index()\n",
    "\n",
    "    # Create the bar plot showing the average elevation for each forest cover type.\n",
    "    # The hue parameter is now set to the same variable as x to avoid a deprecation warning.\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Forest_Cover', y='Elevation', data=average_elevation, hue='Forest_Cover', palette='viridis',\n",
    "                legend=False)\n",
    "\n",
    "    # Add a title and labels for clarity.\n",
    "    plt.title(f'Average Elevation by Forest Cover Type ({method} value)', fontsize=16)\n",
    "    plt.xlabel('Forest Cover Type', fontsize=12)\n",
    "    plt.ylabel('Average Elevation', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels to prevent overlap, making them easier to read.\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Adjust layout to make sure labels are not cut off.\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot.\n",
    "    plt.savefig(path + 'Average_Elevation_Forest_Cover_boxplot.png')\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "276122e9d014ad69",
   "metadata": {},
   "source": [
    "# Bar plot for Average Slope by Forest Cover Type.\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    path = scenario['path']\n",
    "    df = scenario['df']\n",
    "    method = scenario['method']\n",
    "\n",
    "    # Calculate the average elevation for each forest cover type.\n",
    "    average_elevation = df.groupby('Forest_Cover')['Slope'].mean().reset_index()\n",
    "\n",
    "    # Create the bar plot showing the average elevation for each forest cover type.\n",
    "    # The hue parameter is now set to the same variable as x to avoid a deprecation warning.\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Forest_Cover', y='Slope', data=average_elevation, hue='Forest_Cover', palette='viridis',\n",
    "                legend=False)\n",
    "\n",
    "    # Add a title and labels for clarity.\n",
    "    plt.title(f'Average Slope by Forest Cover Type ({method} value)', fontsize=16)\n",
    "    plt.xlabel('Forest Cover Type', fontsize=12)\n",
    "    plt.ylabel('Average Slope', fontsize=12)\n",
    "\n",
    "    # Rotate x-axis labels to prevent overlap, making them easier to read.\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Adjust layout to make sure labels are not cut off.\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display the plot.\n",
    "    plt.savefig(path + 'Average_Slope_Forest_Cover_boxplot.png')\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ccfa33af82eb0b4b",
   "metadata": {},
   "source": [
    "### Analyzing Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf22f096a7ea8296",
   "metadata": {},
   "source": [
    "This section explores the relationship between the categorical features (Area and Soil_Type) and the Forest_Cover target variable. Since these are one-hot encoded, we will visualize their proportions."
   ]
  },
  {
   "cell_type": "code",
   "id": "3175ddae04f836e2",
   "metadata": {},
   "source": [
    "# Identify Wilderness Area columns\n",
    "wilderness_cols = ['Neota', 'Rawah', 'Comanche Peak', 'Cache la Poudre']\n",
    "\n",
    "# Melt the DataFrame to one to analyze the relationship between Forest Cover and Wilderness Area.\n",
    "df_wild_melted = filtered_df.melt(id_vars='Forest_Cover', value_vars=wilderness_cols, var_name='Wilderness_Area',\n",
    "                                  value_name='Is_Present') # The 'Is_Present' column will contain 1s for the rows where a specific wilderness area is present.\n",
    "df_wild_melted"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f2c364f8b1faf050",
   "metadata": {},
   "source": [
    "# Filter for rows where the wilderness area is present (value is 1)\n",
    "df_wild_filtered = df_wild_melted[df_wild_melted['Is_Present'] == 1]\n",
    "# Calculate the counts for each combination of Forest_Cover and Wilderness_Area\n",
    "wild_counts = df_wild_filtered.groupby(['Forest_Cover', 'Wilderness_Area']).size().unstack(fill_value=0)\n",
    "wild_counts"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5af1184bc3023d92",
   "metadata": {},
   "source": [
    "# Calculate the total count for each Forest_Cover type\n",
    "forest_cover_totals = wild_counts.sum(axis=1)\n",
    "# Calculate the normalized proportions\n",
    "wild_proportions = wild_counts.div(forest_cover_totals, axis=0)\n",
    "wild_proportions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e74834d0c2021c7c",
   "metadata": {},
   "source": [
    "# # Create a bar chart to show the proportions\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "wild_proportions.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set_title('Normalized Proportions of Wilderness Areas per Forest Cover Type')\n",
    "ax.set_xlabel('Forest Cover Type')\n",
    "ax.set_ylabel('Proportion')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.legend(title='Wilderness Area', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('wilderness_area_proportions.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "34a4ddc2493e17e2",
   "metadata": {},
   "source": [
    "# Create a heatmap to provide a clearer visualization of the proportions.\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(wild_proportions, cmap='YlGnBu', annot=True, fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Normalized Proportions of Wilderness Areas per Forest Cover Type')\n",
    "plt.xlabel('Wilderness Area')\n",
    "plt.ylabel('Forest Cover Type')\n",
    "plt.tight_layout()\n",
    "plt.savefig('wilderness_area_heatmap.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8b645e9851238fb7",
   "metadata": {},
   "source": [
    "Soil Types"
   ]
  },
  {
   "cell_type": "code",
   "id": "76d96c66bf3a9b0f",
   "metadata": {},
   "source": [
    "# Define the list of Soil_Type columns.\n",
    "soil_cols = [f'Soil_Type{i}' for i in range(1, 41)]\n",
    "\n",
    "# Melt the DataFrame to long format for Soil Types\n",
    "df_soil_melted = filtered_df.melt(id_vars='Forest_Cover', value_vars=soil_cols, var_name='Soil_Type',\n",
    "                                  value_name='Is_Present')\n",
    "df_soil_melted"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71d85eb1b7a51c6b",
   "metadata": {},
   "source": [
    "# Filter for rows where the soil type is present (value is 1)\n",
    "df_soil_filtered = df_soil_melted[df_soil_melted['Is_Present'] == 1]\n",
    "df_soil_filtered"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56bd8d1d68125ff3",
   "metadata": {},
   "source": [
    "# Calculate the counts for each combination of Forest_Cover and Soil_Type\n",
    "soil_counts = df_soil_filtered.groupby(['Forest_Cover', 'Soil_Type']).size().unstack(fill_value=0)\n",
    "soil_counts = soil_counts.reindex(columns=soil_cols, fill_value=0)\n",
    "soil_counts"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f85afd0296f661d",
   "metadata": {},
   "source": [
    "# Calculate the total count for each Forest_Cover type\n",
    "forest_cover_totals = soil_counts.sum(axis=1)\n",
    "# Calculate the normalized proportions\n",
    "soil_proportions = soil_counts.div(forest_cover_totals, axis=0)\n",
    "\n",
    "# Extract the numeric part from the column names (e.g., 'Soil_Type1' -> 1)\n",
    "numeric_labels = [int(col.replace('Soil_Type', '')) for col in soil_proportions.columns]\n",
    "\n",
    "# Set the column names to be the numeric labels\n",
    "soil_proportions.columns = numeric_labels\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.heatmap(soil_proportions, cmap='YlGnBu', annot=True, fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Normalized Proportions of Soil Types per Forest Cover Type')\n",
    "plt.xlabel('Soil Type')\n",
    "plt.ylabel('Forest Cover Type')\n",
    "plt.tight_layout()\n",
    "plt.savefig('soil_type_heatmap.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45644fd6056828e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Export the median value one to csv file as final result"
   ]
  },
  {
   "cell_type": "code",
   "id": "56a236310f35b0c3",
   "metadata": {},
   "source": [
    "for i, scenario in enumerate(scenarios):\n",
    "    if scenario['method'] == \"median\":\n",
    "        scenario['df'].to_csv(f'./dataset_cleaned_filled/forest_cover_filled_median.csv')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
